{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fundamental-gospel",
   "metadata": {},
   "source": [
    "## Lasttests von Machine Learning Modellen zur Qualitätssicherung\n",
    "Dieses Notebook ist Teil von <a href='https://datenverknoten.de/mlops/lasttests-von-machine-learning-modellen-zur-qualitatssicherung/' target='_blank'>einem Artikel</a> auf www.datenverknoten.de.\n",
    "<br>Quelle des verwendeten Datensatzes: https://www.kaggle.com/lirilkumaramal/heart-stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-fortune",
   "metadata": {},
   "source": [
    "## Datenvorbereitung\n",
    "Zunächst wird der Datensatz in ein Pandas DataFrame geladen. Es handelt sich hierbei um verschiedene Parameter aus dem Gesundheitsbereich, die zur Vorhersage eines \n",
    "Infarktes verwendet werden können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "israeli-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_raw = pd.read_csv('rawdata/train_strokes.csv').drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-plenty",
   "metadata": {},
   "source": [
    "Die kategorischen Daten werden mit einem LabelEncoder in Zahlenwerte überführt. Dies verursacht potenziell Probleme, wie bereits im ersten Teil beschrieben wurde. Es wird hier nicht weiter darauf eingegangen. Durch das Encoding werden Zeilen, in denen sich ein NaN in irgendeiner der zu encodierenden Spalten befindet, ausgelassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frozen-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "stroke_pre = stroke_raw.copy()\n",
    "stroke_pre = stroke_pre.dropna()\n",
    "stroke_pre['gender'] = labelencoder.fit_transform(stroke_pre['gender'])\n",
    "stroke_pre['ever_married'] = labelencoder.fit_transform(stroke_pre['ever_married'])\n",
    "stroke_pre['work_type'] = labelencoder.fit_transform(stroke_pre['work_type'])\n",
    "stroke_pre['Residence_type'] = labelencoder.fit_transform(stroke_pre['Residence_type'])\n",
    "stroke_pre['smoking_status'] = labelencoder.fit_transform(stroke_pre['smoking_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-small",
   "metadata": {},
   "source": [
    "Für das Training ist es hilfreich, wenn die Daten skaliert werden, da sonst der Einfluss einer deutlich größeren Variable, wie z.B. Alter, die Wichtigkeit der anderen Variablen negativ beeinflussen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = stroke_pre.columns\n",
    "stroke_pre_unscaled = stroke_pre.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "stroke_pre_scaled = min_max_scaler.fit_transform(stroke_pre_unscaled)\n",
    "stroke_pre_scaled = pd.DataFrame(stroke_pre_scaled,columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-forge",
   "metadata": {},
   "source": [
    "Da es unpraktisch wäre, alle möglichen Subsets der Daten mit stroke = 0 mit einer Größe von 548 zu erstellen und für das Training des Multilayer Perceptron zu nutzen, wird stattdessen ein <i>sliding window</i> verwendet. Dies läuft Instanz für Instanz über alle stroke = 0 Daten und pickt jeweils 548 dieser Instanzen heraus, kombiniert sie mit allen stroke = 1 Daten und erstellt somit einen ausgeglichenen Datensatz. Damit dies möglich wird, werden die beiden Klassen aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varying-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_0 = stroke_pre_scaled[stroke_pre_scaled['stroke']==0]\n",
    "stroke_1 = stroke_pre_scaled[stroke_pre_scaled['stroke']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-charge",
   "metadata": {},
   "source": [
    "In der nächsten Zelle wird das Multilayer Perceptron (MLP) trainiert. Dabei wird der zuvor beschriebene <i>sliding window</i> Ansatz verwendet. Für jedes Modell wird die Genauigkeit bestimmt. Das Modell, welches die höchste Genauigkeit besitzt, lässt sich nach Beendigung aller Trainingsdurchläufe in der Variable <i>best_clf</i> finden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "personal-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "best_clf = None\n",
    "highest_accuracy = None\n",
    "\n",
    "# Sliding window wie zuvor auch\n",
    "for i in range(0,1000):\n",
    "    if(i % 100 == 0):\n",
    "        print(i)\n",
    "    # Zusammensetzen des Datensatzes\n",
    "    stroke_0_set = stroke_0.sample(n=len(stroke_1))\n",
    "    attached_set = stroke_0_set.append(stroke_1)\n",
    "    X = attached_set.drop(columns=['stroke'])\n",
    "    y = attached_set['stroke']\n",
    "    # Es wird ein Train-Test Split erstellt\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=2)\n",
    "\n",
    "    # Die berechnete Accuracy soll auf die Eigenschaften des Trainings- und Testdatensatzes bezogen werden. \n",
    "    # Darum werden die Mittelwerte der einzelnen Features bestimmt.\n",
    "    stats_1 = X_train.mean().to_dict()\n",
    "    stats_2 = X_test.mean().to_dict()\n",
    "    # Das MLP wird trainiert\n",
    "    clf_mlp = MLPClassifier(random_state=1, max_iter=1500,hidden_layer_sizes=(5, 2))\n",
    "    clf_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    acc = clf_mlp.score(X_test,y_test)\n",
    "    if(highest_accuracy == None or acc > highest_accuracy):\n",
    "        highest_accuracy = acc\n",
    "        best_clf = clf_mlp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-divorce",
   "metadata": {},
   "source": [
    "Als nächstes wird angegeben, unter welcher Adresse die zentrale registry zu finden ist. In dieser werden Referenzen zu den erstellten und getrackten Modellen gespeichert. Es gibt verschiedene kompatible Datenbanktypen. Hier wird eine SQLite Datenbank verwendet. Die Modelle selber liegen als Datei im Verzeichnis vor, das beim Start des MLFlow Servers angegeben wird. Die Tracking URI bestimmt, wo der MLFlow Server gestartet wurde und wohin die Parameter geloggt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becoming-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_uri = 'sqlite:///mlflow.db'\n",
    "tracking_uri = 'http://localhost:5000'\n",
    " \n",
    "mlflow.set_registry_uri(registry_uri)\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-allowance",
   "metadata": {},
   "source": [
    "Im nächsten Schritt werden nun die Genauigkeit und das Modell gelogt, damit die Genauigkeit im GUI des MLFlow Servers sichtbar ist. Das Modell wird direkt registriert. Ab diesem Moment kann es (im GUI von MLFlow) in den Status Staging oder Productive verschoben werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "durable-output",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'mlp_model'.\n",
      "2021/04/02 22:39:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: mlp_model, version 1\n",
      "Created version '1' of model 'mlp_model'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param(\"Accuracy\", highest_accuracy)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model = best_clf,\n",
    "        artifact_path = \"mlpmodel\",\n",
    "        registered_model_name = \"mlp_model\"   \n",
    "    )\n",
    "    \n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-laser",
   "metadata": {},
   "source": [
    "Hier wird die run_id abgefragt. Diese besteht aus einer langen Zeichenkette und in einem gleichnamigen Ordner werden die Modellartefakte gespeichert. Die id wird benötigt, um einen Webserver zu starten, welcher das Modell als Webservice bereitstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "offshore-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "runid = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generous-alberta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0703fe95356f4133a05ed2ed696d2c0f'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(runid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-community",
   "metadata": {},
   "source": [
    "Der Befehl zum Bereitstellen des Modells in einem Webserver würde dann wie folgt aussehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mlflow models serve -p 5005 -m mlruns/0/'+str(runid)+'/artifacts/mlpmodel --no-conda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-assurance",
   "metadata": {},
   "source": [
    "Hier ist noch zusätzlich gezeigt, wie in Python ein request an das bereitgestellte Modell gesendet werden kann. Dafür muss der Webserver gestartet sein, wie im vorherigen Befehl beschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "double-strike",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1.0]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "host = '127.0.0.1'\n",
    "port = '5005'\n",
    "\n",
    "url = f'http://{host}:{port}/invocations'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "http_data = '{\"columns\":[\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"avg_glucose_level\",\"bmi\",\"smoking_status\"],\"data\":[[0.5,1.0,0.0,0.0,1.0,0.5,1.0,0.1519657685,0.1904761905,0.5]]}'\n",
    "\n",
    "r = requests.post(url=url, headers=headers, data=http_data)\n",
    "\n",
    "print(f'Predictions: {r.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-relationship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
